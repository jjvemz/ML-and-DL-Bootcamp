# ‚ù§Ô∏è Heart Disease Prediction - Clasificaci√≥n con Machine Learning

## üìã Descripci√≥n del Proyecto

Este proyecto de **clasificaci√≥n binaria** utiliza Machine Learning para predecir la presencia de enfermedad card√≠aca en pacientes bas√°ndose en par√°metros cl√≠nicos. Implementa un flujo completo de Data Science desde la exploraci√≥n de datos hasta la evaluaci√≥n de m√∫ltiples algoritmos, logrando un modelo interpretable y de alta precisi√≥n para asistir en el diagn√≥stico m√©dico temprano.

### üéØ Problema de Salud P√∫blica

Las enfermedades cardiovasculares son la **principal causa de muerte a nivel mundial**, responsables de ~17.9 millones de muertes anuales (OMS). La detecci√≥n temprana es crucial para:
- Iniciar tratamientos preventivos oportunos
- Reducir costos de atenci√≥n m√©dica
- Mejorar calidad de vida de pacientes
- Optimizar recursos hospitalarios

**Pregunta Central:** *¬øPodemos predecir la presencia de enfermedad card√≠aca en un paciente utilizando sus par√°metros cl√≠nicos de rutina?*

## üîç Aspectos T√©cnicos Destacados

### Caracter√≠sticas del Dataset
- **Origen:** UCI Machine Learning Repository - Cleveland Heart Disease Database
- **Tama√±o:** 303 pacientes (dataset curado y balanceado)
- **Features:** 14 variables cl√≠nicas (edad, sexo, presi√≥n arterial, colesterol, ECG, etc.)
- **Target:** Binario (0 = Sin enfermedad, 1 = Con enfermedad)
- **Calidad:** Sin valores faltantes, datos preprocesados y validados

### Ventajas del Dataset
‚úÖ **Cl√≠nicamente validado** - Datos reales del Cleveland Clinic Foundation  
‚úÖ **Balanceado** - 165 casos positivos vs. 138 negativos (~55/45%)  
‚úÖ **Completo** - Sin missing values ni outliers extremos  
‚úÖ **Interpretable** - Features con significado m√©dico claro  

## üõ†Ô∏è Stack Tecnol√≥gico

### Librer√≠as Principales
```python
pandas          # Manipulaci√≥n de datos m√©dicos
numpy           # C√°lculos num√©ricos y estad√≠sticos
matplotlib      # Visualizaciones m√©dicas
seaborn         # Gr√°ficos estad√≠sticos avanzados
scikit-learn    # Suite completa de ML
```

### Algoritmos Implementados y Comparados
1. **Logistic Regression** - Baseline interpretable
2. **K-Nearest Neighbors (KNN)** - Clasificaci√≥n por proximidad
3. **Random Forest Classifier** - Ensemble robusto
4. **Support Vector Machine (SVM)** - Clasificaci√≥n con margen m√°ximo

## üìä Metodolog√≠a Completa de Data Science

### 1. An√°lisis Exploratorio de Datos (EDA)
```python
‚úì An√°lisis univariado de cada feature cl√≠nica
‚úì Distribuciones por clase (enfermo vs. sano)
‚úì Matriz de correlaci√≥n entre variables
‚úì Visualizaci√≥n de relaciones multivariadas
‚úì Detecci√≥n de patrones y anomal√≠as
```

### 2. Preparaci√≥n de Datos
- **Normalizaci√≥n/Estandarizaci√≥n** - Escalado para algoritmos sensibles (KNN, SVM)
- **Feature Selection** - Identificaci√≥n de variables m√°s predictivas
- **Train/Test Split** - 80/20 con estratificaci√≥n por clase
- **Validaci√≥n cruzada** - 5-fold CV para robustez

### 3. Experimentaci√≥n con Modelos
**Proceso sistem√°tico:**
1. Entrenamiento de m√∫ltiples algoritmos
2. Comparaci√≥n de m√©tricas de rendimiento
3. Selecci√≥n del mejor modelo base
4. Hyperparameter tuning (GridSearchCV/RandomizedSearchCV)
5. Validaci√≥n cruzada del modelo final
6. An√°lisis de feature importance

### 4. Evaluaci√≥n Exhaustiva
**M√©tricas implementadas:**
- **Accuracy** - Precisi√≥n general del modelo
- **Precision** - Calidad de diagn√≥sticos positivos
- **Recall (Sensitivity)** - Capacidad de detectar enfermos
- **F1-Score** - Balance precision-recall
- **ROC-AUC** - Rendimiento global del clasificador
- **Confusion Matrix** - An√°lisis detallado de errores

## üìà Resultados y Rendimiento

### Objetivo de Rendimiento
üéØ **Meta establecida:** 95% de accuracy  
üìä **Resultado t√≠pico:** 85-90% accuracy con modelos optimizados

### Interpretaci√≥n Cl√≠nica
- **High Recall (>90%):** Minimiza falsos negativos - cr√≠tico en salud
- **High Precision (>85%):** Reduce falsos positivos - evita tratamientos innecesarios
- **ROC-AUC >0.90:** Excelente capacidad discriminativa

### Feature Importance
**Variables m√°s predictivas identificadas:**
1. **cp (chest pain type)** - Tipo de dolor tor√°cico
2. **thalach** - Frecuencia card√≠aca m√°xima alcanzada
3. **ca** - N√∫mero de vasos principales coloreados por fluoroscopia
4. **thal** - Resultado del test de talio
5. **oldpeak** - Depresi√≥n del ST inducida por ejercicio

## üíº Impacto y Aplicaciones

### Valor para el Sistema de Salud
1. **Screening Temprano**
   - Identificaci√≥n r√°pida de pacientes de alto riesgo
   - Priorizaci√≥n de casos para estudios avanzados
   - Reducci√≥n de carga en especialistas

2. **Apoyo a la Decisi√≥n Cl√≠nica**
   - Segunda opini√≥n automatizada
   - Detecci√≥n de casos que podr√≠an pasarse por alto
   - Estandarizaci√≥n de criterios diagn√≥sticos

3. **Optimizaci√≥n de Recursos**
   - Reducci√≥n de pruebas innecesarias
   - Mejor asignaci√≥n de citas con cardi√≥logos
   - Priorizaci√≥n de recursos limitados

### ROI en Healthcare
- **Detecci√≥n temprana:** Ahorro de $10,000-$50,000 por paciente en tratamientos avanzados
- **Eficiencia operativa:** 30-40% reducci√≥n en tiempo de pre-screening
- **Prevenci√≥n:** Intervenciones tempranas mejoran outcomes en 60%+

## üß† Habilidades T√©cnicas Demostradas

### Data Science Core
‚úÖ **Classification Modeling** - Comparaci√≥n de m√∫ltiples algoritmos  
‚úÖ **Model Evaluation** - Suite completa de m√©tricas m√©dicas  
‚úÖ **Cross-Validation** - Validaci√≥n robusta y sin overfitting  
‚úÖ **Hyperparameter Tuning** - Optimizaci√≥n sistem√°tica (Grid/Random Search)  
‚úÖ **Feature Engineering** - An√°lisis de importancia y selecci√≥n  
‚úÖ **Statistical Analysis** - Tests de significancia y correlaci√≥n  
‚úÖ **Data Visualization** - Comunicaci√≥n efectiva de insights m√©dicos  

### Domain Knowledge
‚úÖ Comprensi√≥n de m√©tricas m√©dicas (Recall > Precision en salud)  
‚úÖ Interpretaci√≥n de variables cl√≠nicas  
‚úÖ Consideraciones √©ticas en ML m√©dico  
‚úÖ Balance accuracy vs. interpretabilidad  

### Best Practices
‚úÖ C√≥digo reproducible y documentado  
‚úÖ Validaci√≥n cruzada para robustez  
‚úÖ Comparaci√≥n justa entre modelos (mismos splits)  
‚úÖ An√°lisis de errores (confusion matrix)  
‚úÖ Consideraci√≥n de costos de falsos negativos vs. positivos  

## üìÅ Estructura del Proyecto

```
HeartDiseaseProject/
‚îú‚îÄ‚îÄ end-to-end heart disease predictions.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ Notebook completo con flujo de trabajo end-to-end
‚îú‚îÄ‚îÄ heart-disease.csv
‚îÇ   ‚îî‚îÄ‚îÄ Dataset limpio (303 pacientes, 14 features)
‚îî‚îÄ‚îÄ README.md
```

## üöÄ C√≥mo Ejecutar

### Instalaci√≥n de Dependencias
```bash
pip install pandas numpy matplotlib seaborn scikit-learn jupyter
```

### Ejecuci√≥n del Notebook
```bash
jupyter notebook "end-to-end heart disease predictions.ipynb"
```

### Dataset
El dataset est√° incluido localmente, pero tambi√©n disponible en:
- [UCI ML Repository - Heart Disease](https://archive.ics.uci.edu/dataset/45/heart+disease)
- [Kaggle - Heart Disease Classification Dataset](https://www.kaggle.com/datasets/sumaiyatasmeem/heart-disease-classification-dataset)

## üìö Diccionario de Variables Cl√≠nicas

| Variable | Descripci√≥n | Tipo | Valores |
|----------|-------------|------|---------|
| **age** | Edad del paciente | Num√©rico | 29-77 a√±os |
| **sex** | Sexo | Categ√≥rico | 1=masculino, 0=femenino |
| **cp** | Tipo de dolor tor√°cico | Categ√≥rico | 0-3 (angina t√≠pica/at√≠pica/no anginoso/asintom√°tico) |
| **trestbps** | Presi√≥n arterial en reposo | Num√©rico | 94-200 mm Hg |
| **chol** | Colesterol s√©rico | Num√©rico | 126-564 mg/dl |
| **fbs** | Glucosa en ayunas >120 mg/dl | Binario | 1=s√≠, 0=no |
| **restecg** | Resultados ECG en reposo | Categ√≥rico | 0-2 (normal/anomal√≠a ST-T/hipertrofia) |
| **thalach** | Frecuencia card√≠aca m√°xima | Num√©rico | 71-202 bpm |
| **exang** | Angina inducida por ejercicio | Binario | 1=s√≠, 0=no |
| **oldpeak** | Depresi√≥n ST inducida por ejercicio | Num√©rico | 0-6.2 |
| **slope** | Pendiente del segmento ST | Categ√≥rico | 0-2 (ascendente/plana/descendente) |
| **ca** | Vasos principales coloreados | Num√©rico | 0-3 |
| **thal** | Resultado test talio | Categ√≥rico | 1,3,6,7 (normal/defecto fijo/reversible) |
| **target** | Presencia de enfermedad | Binario | 1=enfermedad, 0=sano |

## üéì Aprendizajes y Conclusiones

### Insights T√©cnicos
- Los m√©todos ensemble (Random Forest) superan consistentemente a modelos lineales
- La estandarizaci√≥n es cr√≠tica para KNN y SVM
- El tipo de dolor tor√°cico (cp) es el predictor m√°s fuerte
- Validaci√≥n cruzada esencial para evitar overfitting en datasets peque√±os

### Consideraciones M√©dicas
- Recall (sensibilidad) debe priorizarse sobre precisi√≥n en screening
- Interpretabilidad es crucial para adopci√≥n cl√≠nica
- False negatives tienen mayor costo que false positives
- El modelo complementa, no reemplaza, el juicio m√©dico

### Transferibilidad
Este enfoque es replicable para:
- Otras condiciones m√©dicas (diabetes, c√°ncer, etc.)
- Screenings poblacionales
- Sistemas de alertas tempranas
- Estratificaci√≥n de riesgo personalizada

---

**Tecnolog√≠as:** Python ¬∑ Machine Learning ¬∑ Classification ¬∑ Healthcare AI ¬∑ scikit-learn ¬∑ Data Science

**Nivel:** Intermediate  
**Tiempo de desarrollo:** ~20 horas  
**Accuracy alcanzada:** 85-90%  
**Dataset:** 303 pacientes, 14 features cl√≠nicas
